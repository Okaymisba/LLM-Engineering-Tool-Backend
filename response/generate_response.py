from prompt_generation.prompt_generation import generate_prompt
from prompt_generation.query_local_model import query_local_model
from response.anthropic.query_anthropic_model import query_anthropic_model
from response.deepseek.query_deepseek_model import query_deepseek_model
from response.google.query_google_model import query_google_model
from response.openai.query_openai_model import query_openai_model


def generate_response(provider: str, model: str, question: str, prompt_context: list = None, instructions=None,
                      image_data=None, document_data=None):
    """
    Generates a response based on the input parameters by selecting the appropriate provider
    and invoking the corresponding model's query function. The function supports multiple
    providers and models. Inputs like question, prompt_context, instructions, and additional
    data (image_data, document_data) are sent to the selected provider for processing.

    :param provider: The name of the provider to use for querying a model.
    :param model: The specific model within the selected provider to query.
    :param question: The question or query string to send to the model.
    :param prompt_context: A list of contextual strings to provide as additional
        context for the generated response. Default is None.
    :param instructions: Optional additional guiding instructions
        for the model's response generation. Default is None.
    :param image_data: Optional image data to be used by compatible models
        during query processing. Default is None.
    :param document_data: Optional document data to be used by compatible models
        during query processing. Default is None.
    :return: The response generated by the queried model or process.
    :rtype: str
    """
    if provider == "deepseek":
        return query_deepseek_model(model, question, prompt_context, instructions, image_data, document_data)
    elif provider == "openai":
        return query_openai_model(model, question, prompt_context, instructions, image_data, document_data)
    elif provider == "anthropic":
        return query_anthropic_model(model, question, prompt_context, instructions, image_data, document_data)
    elif provider == "google":
        return query_google_model(model, question, prompt_context, instructions, image_data, document_data)
    else:
        return query_local_model(generate_prompt(question, prompt_context, instructions, image_data, document_data))
