import os

import openai
from dotenv import load_dotenv

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")


def query_openai_model(model, question, prompt_context=None, instructions=None):
    """
    Executes a query to the OpenAI model and fetches the response based on given
    parameters. This function prepares the conversation context by appending
    instructional and contextual messages as needed and then queries the model
    with the user's question.

    :param model: The name of the OpenAI model to query (e.g., "gpt-3.5-turbo").
    :type model: str
    :param question: The user's question to send to the model.
    :type question: str
    :param prompt_context: Additional context about the topic to provide
        relevant information for the model's response. Optional.
    :type prompt_context: str, optional
    :param instructions: System-level instructions to guide the model's
        behavior and response style. Optional.
    :type instructions: str, optional
    :return: The response content generated by the model in
        reply to the submitted question.
    :rtype: str
    """
    messages = []

    if instructions:
        messages.append({"role": "system", "content": instructions})

    if prompt_context:
        messages.append({"role": "system", "content": f"Here is the context: {prompt_context}"})

    messages.append({"role": "user", "content": question})

    response = openai.completions.create(
        model=model,
        prompt=messages
    )

    return response["choices"][0]["message"]["content"]
