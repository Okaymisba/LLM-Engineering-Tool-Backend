import faiss
import numpy as np
from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.orm import Session

from models import get_db
from models.api_list import APIList
from models.documents import Documents
from models.embeddings import Embeddings
from response.generate_response import generate_response

router = APIRouter()


def load_faiss_index(embeddings):
    dimension = embeddings[0][1].shape[0]
    index = faiss.IndexFlatL2(dimension)
    id_map = {}

    for idx, (doc_id, embedding) in enumerate(embeddings):
        index.add(np.expand_dims(embedding, axis=0))
        id_map[idx] = doc_id

    return index, id_map


@router.get("/ask/")
def ask_question(api_key: str, provider: str, model: str, question: str, db: Session = Depends(get_db)):
    """
    Handles a GET request to generate a response to a given question. The function authenticates an API key,
    retrieves all related documents from the database, processes embeddings, queries FAISS for the most similar
    documents, and uses a provider-specific model to generate a response.

    :param api_key: The API key used to authenticate the request
    :param provider: The AI model provider to be used for generating the response
    :param model: The name or identifier of the specific model provided by the AI provider
    :param question: The user's input question for which an answer is requested
    :param db: The database session used for querying API keys, documents, and embeddings
    :return: A JSON response containing the answer generated by the AI model, context from similar documents, and a success flag
    :rtype: dict
    """

    api_entry = APIList.get_by_api_key(db, api_key)
    if not api_entry:
        raise HTTPException(status_code=403, detail="Invalid or expired API key.")

    documents = db.query(Documents).filter(Documents.api_id == api_entry.id).all()
    if not documents:
        raise HTTPException(status_code=404, detail="No documents found for the given API key.")

    embeddings = []
    for document in documents:
        embedding_entry = db.query(Embeddings).filter(Embeddings.document_id == document.api_id).first()
        if embedding_entry:
            embeddings.append((document.document_id, np.frombuffer(embedding_entry.embedding, dtype=np.float32)))

    if not embeddings:
        raise HTTPException(status_code=404, detail="No embeddings found for the associated documents.")

    try:
        index, id_map = load_faiss_index(embeddings)
    except ValueError as e:
        raise HTTPException(status_code=500, detail=str(e))

    question_embedding = np.random.rand(len(embeddings[0][1])).astype('float32')

    top_k = 3
    distances, indices = index.search(np.expand_dims(question_embedding, axis=0), top_k)

    most_similar_documents = []
    for idx in indices[0]:
        if idx != -1:
            most_similar_doc_id = id_map.get(idx)
            if most_similar_doc_id:
                document = db.query(Documents).filter(Documents.document_id == most_similar_doc_id).first()
                if document:
                    most_similar_documents.append(document)

    if not most_similar_documents:
        raise HTTPException(status_code=500, detail="Could not retrieve the most similar document.")

    prompt_context = []
    for document in most_similar_documents:
        prompt_context.append(document.chunk_text)
    instructions = api_entry.instructions

    response = generate_response(provider, model, question, instructions, prompt_context)

    return {
        "success": True,
        "answer": response,
        "context": prompt_context,
    }
